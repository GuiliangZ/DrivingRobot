{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bbb519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import casadi as cs\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "\n",
    "import torch\n",
    "from acados_template import AcadosOcp, AcadosOcpSolver, AcadosModel\n",
    "\n",
    "\n",
    "class DROptimizer:\n",
    "    def __init__(self, t_horizon, q_cost=None, r_cost=None,\n",
    "                 \n",
    "                  model_name=\"DR_acados_mpc\", solver_options=None):\n",
    "        nx = key_model.x.size()[0]\n",
    "        nu = key_model.u.size()[0]\n",
    "        ny = nx + nu\n",
    "        n_param = key_model.p.size()[0] if isinstance(key_model.p, cs.MX) else 0\n",
    "\n",
    "        acados_source_path = os.environ['ACADOS_SOURCE_DIR']\n",
    "        sys.path.insert(0, '../common')\n",
    "\n",
    "        # Create OCP object to formulate the optimization\n",
    "        ocp = AcadosOcp()\n",
    "        ocp.acados_include_path = acados_source_path + '/include'\n",
    "        ocp.acados_lib_path = acados_source_path + '/lib'\n",
    "        ocp.model = key_model\n",
    "        ocp.dims.N = self.N\n",
    "        ocp.solver_options.tf = t_horizon\n",
    "\n",
    "        # Initialize parameters\n",
    "        ocp.dims.np = n_param\n",
    "        ocp.parameter_values = np.zeros(n_param)\n",
    "\n",
    "        ocp.cost.cost_type = 'LINEAR_LS'\n",
    "        ocp.cost.cost_type_e = 'LINEAR_LS'\n",
    "\n",
    "        ocp.cost.W = np.diag(np.concatenate((q_diagonal, r_cost)))\n",
    "        ocp.cost.W_e = np.diag(q_diagonal)\n",
    "        terminal_cost = 0 if solver_options is None or not solver_options[\"terminal_cost\"] else 1\n",
    "        ocp.cost.W_e *= terminal_cost\n",
    "\n",
    "        ocp.cost.Vx = np.zeros((ny, nx))\n",
    "        ocp.cost.Vx[:nx, :nx] = np.eye(nx)\n",
    "        ocp.cost.Vu = np.zeros((ny, nu))\n",
    "        ocp.cost.Vu[-4:, -4:] = np.eye(nu)\n",
    "\n",
    "        ocp.cost.Vx_e = np.eye(nx)\n",
    "\n",
    "        # Initial reference trajectory (will be overwritten)\n",
    "        x_ref = np.zeros(nx)\n",
    "        ocp.cost.yref = np.concatenate((x_ref, np.array([0.0, 0.0, 0.0, 0.0])))\n",
    "        ocp.cost.yref_e = x_ref\n",
    "\n",
    "        # Initial state (will be overwritten)\n",
    "        ocp.constraints.x0 = x_ref\n",
    "\n",
    "        # Set constraints\n",
    "        ocp.constraints.lbu = np.array([self.min_u] * 4)\n",
    "        ocp.constraints.ubu = np.array([self.max_u] * 4)\n",
    "        ocp.constraints.idxbu = np.array([0, 1, 2, 3])\n",
    "\n",
    "        # Solver options\n",
    "        ocp.solver_options.qp_solver = 'FULL_CONDENSING_HPIPM'\n",
    "        ocp.solver_options.hessian_approx = 'GAUSS_NEWTON'\n",
    "        ocp.solver_options.integrator_type = 'ERK'\n",
    "        ocp.solver_options.print_level = 0\n",
    "        ocp.solver_options.nlp_solver_type = 'SQP_RTI' if solver_options is None else solver_options[\"solver_type\"]\n",
    "\n",
    "        # Compile acados OCP solver if necessary\n",
    "        json_file = os.path.join(self.acados_models_dir, key_model.name + '_acados_ocp.json')\n",
    "        self.acados_ocp_solver[key] = AcadosOcpSolver(ocp, json_file=json_file)\n",
    "\n",
    "\n",
    "    def clear_acados_model(self):\n",
    "        \"\"\"\n",
    "        Removes previous stored acados models to avoid name conflicts.\n",
    "        \"\"\"\n",
    "\n",
    "        json_file = os.path.join(self.acados_models_dir, 'acados_ocp.json')\n",
    "        if os.path.exists(json_file):\n",
    "            os.remove(os.path.join(os.getcwd(), json_file))\n",
    "        compiled_model_dir = os.path.join(os.getcwd(), 'c_generated_code')\n",
    "        if os.path.exists(compiled_model_dir):\n",
    "            shutil.rmtree(compiled_model_dir)\n",
    "\n",
    "\n",
    "   def acados_setup_model(self, nominal, model_name):\n",
    "        \"\"\"\n",
    "        Builds an Acados symbolic models using CasADi expressions.\n",
    "        :param model_name: name for the acados model. Must be different from previously used names or there may be\n",
    "        problems loading the right model.\n",
    "        :param nominal: CasADi symbolic nominal model of the quadrotor: f(self.x, self.u) = x_dot, dimensions 13x1.\n",
    "        :return: Returns a total of three outputs, where m is the number of GP's in the GP ensemble, or 1 if no GP:\n",
    "            - A dictionary of m AcadosModel of the GP-augmented quadrotor\n",
    "            - A dictionary of m CasADi symbolic nominal dynamics equations with GP mean value augmentations (if with GP)\n",
    "        :rtype: dict, dict, cs.MX\n",
    "        \"\"\"\n",
    "\n",
    "        def fill_in_acados_model(x, u, p, dynamics, name):\n",
    "\n",
    "            x_dot = cs.MX.sym('x_dot', dynamics.shape)\n",
    "            f_impl = x_dot - dynamics\n",
    "\n",
    "            # Dynamics model\n",
    "            model = AcadosModel()\n",
    "            model.f_expl_expr = dynamics\n",
    "            model.f_impl_expr = f_impl\n",
    "            model.x = x\n",
    "            model.xdot = x_dot\n",
    "            model.u = u\n",
    "            model.p = p\n",
    "            model.name = name\n",
    "\n",
    "            return model\n",
    "\n",
    "        acados_models = {}\n",
    "        dynamics_equations = {}\n",
    "\n",
    "        # Run GP inference if GP's available\n",
    "        if self.gp_reg_ensemble is not None:\n",
    "\n",
    "            # Feature vector are the elements of x and u determined by the selection matrix B_z. The trigger var is used\n",
    "            # to select the gp-specific state estimate in the first optimization node, and the regular integrated state\n",
    "            # in the rest. The computing of the features z is done within the GPEnsemble.\n",
    "            gp_x = self.gp_x * self.trigger_var + self.x * (1 - self.trigger_var)\n",
    "            #  Transform velocity to body frame\n",
    "            v_b = v_dot_q(gp_x[7:10], quaternion_inverse(gp_x[3:7]))\n",
    "            gp_x = cs.vertcat(gp_x[:7], v_b, gp_x[10:])\n",
    "            gp_u = self.u\n",
    "\n",
    "            gp_dims = self.gp_reg_ensemble.dim_idx\n",
    "\n",
    "            # Get number of models in GP\n",
    "            for i in range(self.gp_reg_ensemble.n_models):\n",
    "                # Evaluate cluster of the GP ensemble\n",
    "                cluster_id = {k: [v] for k, v in zip(gp_dims, i * np.ones_like(gp_dims, dtype=int))}\n",
    "                outs = self.gp_reg_ensemble.predict(gp_x, gp_u, return_cov=False, gp_idx=cluster_id, return_z=False)\n",
    "\n",
    "                # Unpack prediction outputs. Transform back to world reference frame\n",
    "                outs = self.add_missing_states(outs)\n",
    "                gp_means = v_dot_q(outs[\"pred\"], gp_x[3:7])\n",
    "                gp_means = self.remove_extra_states(gp_means)\n",
    "\n",
    "                # Add GP mean prediction\n",
    "                dynamics_equations[i] = nominal + cs.mtimes(self.B_x, gp_means)\n",
    "\n",
    "                x_ = self.x\n",
    "                dynamics_ = dynamics_equations[i]\n",
    "\n",
    "                # Add again the gp augmented dynamics for the GP state\n",
    "                dynamics_ = cs.vertcat(dynamics_)\n",
    "                dynamics_equations[i] = cs.vertcat(dynamics_equations[i])\n",
    "\n",
    "                i_name = model_name + \"_domain_\" + str(i)\n",
    "\n",
    "                params = cs.vertcat(self.gp_x, self.trigger_var)\n",
    "                acados_models[i] = fill_in_acados_model(x=x_, u=self.u, p=params, dynamics=dynamics_, name=i_name)\n",
    "\n",
    "        elif self.mlp_regressor is not None:\n",
    "            state = self.gp_x * self.trigger_var + self.x * (1 - self.trigger_var)\n",
    "            #  Transform velocity to body frame\n",
    "            v_b = v_dot_q(state[7:10], quaternion_inverse(state[3:7]))\n",
    "            state = cs.vertcat(state[:7], v_b, state[10:])\n",
    "            mlp_in = v_b\n",
    "\n",
    "            if self.mlp_conf['torque_output']:\n",
    "                mlp_in = cs.vertcat(mlp_in, state[10:])\n",
    "\n",
    "            if self.mlp_conf['u_inp']:\n",
    "                mlp_in = cs.vertcat(mlp_in, self.u)\n",
    "\n",
    "            if self.mlp_conf['ground_map_input']:\n",
    "                map_conf = GroundEffectMapConfig\n",
    "                map = GroundMapWithBox(np.array(map_conf.box_min),\n",
    "                                       np.array(map_conf.box_max),\n",
    "                                       map_conf.box_height,\n",
    "                                       horizon=map_conf.horizon,\n",
    "                                       resolution=map_conf.resolution)\n",
    "\n",
    "                self._map_res = map_conf.resolution\n",
    "\n",
    "                self._static_ground_map, self._org_to_map_org = map.at(np.array(map_conf.origin))\n",
    "                ground_map_dx = cs.MX(self._static_ground_map)\n",
    "\n",
    "                idx = cs.DM(np.arange(0, 3, 1))\n",
    "\n",
    "                x, y, z = state[0], state[1], state[2]\n",
    "                orientation = state[3:7]\n",
    "\n",
    "                x_idxs = cs.floor((x - self._org_to_map_org[0]) / map_conf.resolution) + idx - 1\n",
    "                y_idxs = cs.floor((y - self._org_to_map_org[1]) / map_conf.resolution) + idx - 1\n",
    "                ground_patch = ground_map_dx[x_idxs, y_idxs]\n",
    "\n",
    "                relative_ground_patch = z - ground_patch\n",
    "                relative_ground_patch = 4 * (cs.fmax(cs.fmin(relative_ground_patch, 0.5), 0.0) - 0.25)\n",
    "\n",
    "                ground_effect_in = cs.vertcat(cs.reshape(relative_ground_patch, 9, 1), orientation*0)\n",
    "\n",
    "                mlp_in = cs.vertcat(mlp_in, ground_effect_in)\n",
    "\n",
    "            if not self.mlp_conf['approximated']:\n",
    "                outs = self.mlp_regressor(mlp_in)\n",
    "            else:\n",
    "                outs = self.mlp_regressor.approx(mlp_in, order=self.mlp_conf['approx_order'], parallel=False)\n",
    "\n",
    "            if self.mlp_conf['torque_output']:\n",
    "                outs_force = outs[:3]\n",
    "                outs_torque = outs[3:]\n",
    "                mlp_means = cs.vertcat(v_dot_q(outs_force, state[3:7]), outs_torque)\n",
    "            else:\n",
    "                # Unpack prediction outputs. Transform back to world reference frame\n",
    "                mlp_means = v_dot_q(outs, state[3:7])\n",
    "\n",
    "            # Add GP mean prediction\n",
    "            dynamics_equations[0] = nominal + cs.mtimes(self.B_x, mlp_means)\n",
    "\n",
    "            x_ = self.x\n",
    "            dynamics_ = dynamics_equations[0]\n",
    "\n",
    "            # Add again the gp augmented dynamics for the GP state\n",
    "            dynamics_ = cs.vertcat(dynamics_)\n",
    "            dynamics_equations[0] = cs.vertcat(dynamics_equations[0])\n",
    "\n",
    "            i_name = model_name + \"_domain_\" + str(0)\n",
    "\n",
    "            if not self.mlp_conf['approximated']:\n",
    "                params = cs.vertcat(self.gp_x, self.trigger_var)\n",
    "            else:\n",
    "                params = cs.vertcat(self.gp_x, self.trigger_var,\n",
    "                                    self.mlp_regressor.sym_approx_params(order=self.mlp_conf['approx_order'],\n",
    "                                                                         flat=True))\n",
    "            acados_models[0] = fill_in_acados_model(x=x_, u=self.u, p=params, dynamics=dynamics_, name=i_name)\n",
    "\n",
    "        else:\n",
    "\n",
    "            # No available GP so return nominal dynamics\n",
    "            dynamics_equations[0] = nominal\n",
    "\n",
    "            x_ = self.x\n",
    "            dynamics_ = nominal\n",
    "\n",
    "            acados_models[0] = fill_in_acados_model(x=x_, u=self.u, p=[], dynamics=dynamics_, name=model_name)\n",
    "\n",
    "        return acados_models, dynamics_equations\n",
    "\n",
    "\n",
    "    def run_optimization(self, initial_state=None, use_model=0, return_x=False, gp_regression_state=None):\n",
    "        \"\"\"\n",
    "        Optimizes a trajectory to reach the pre-set target state, starting from the input initial state, that minimizes\n",
    "        the quadratic cost function and respects the constraints of the system\n",
    "\n",
    "        :param initial_state: 13-element list of the initial state. If None, 0 state will be used\n",
    "        :param use_model: integer, select which model to use from the available options.\n",
    "        :param return_x: bool, whether to also return the optimized sequence of states alongside with the controls.\n",
    "        :param gp_regression_state: 13-element list of state for GP prediction. If None, initial_state will be used.\n",
    "        :return: optimized control input sequence (flattened)\n",
    "        \"\"\"\n",
    "\n",
    "        if initial_state is None:\n",
    "            initial_state = [0, 0, 0] + [1, 0, 0, 0] + [0, 0, 0] + [0, 0, 0]\n",
    "\n",
    "        # Set initial state. Add gp state if needed\n",
    "        x_init = initial_state\n",
    "        x_init = np.stack(x_init)\n",
    "\n",
    "        # Set initial condition, equality constraint\n",
    "        self.acados_ocp_solver[use_model].set(0, 'lbx', x_init)\n",
    "        self.acados_ocp_solver[use_model].set(0, 'ubx', x_init)\n",
    "\n",
    "        # Set parameters\n",
    "        if self.with_gp:\n",
    "            gp_state = gp_regression_state if gp_regression_state is not None else initial_state\n",
    "            self.acados_ocp_solver[use_model].set(0, 'p', np.array(gp_state + [1]))\n",
    "            for j in range(1, self.N):\n",
    "                self.acados_ocp_solver[use_model].set(j, 'p', np.array([0.0] * (len(gp_state) + 1)))\n",
    "\n",
    "        if self.with_mlp:\n",
    "            if self.x_opt_acados is None:\n",
    "                if isinstance(self.target[0], list):\n",
    "                    self.x_opt_acados = np.expand_dims(\n",
    "                        np.concatenate([self.target[i] for i in range(len(self.target))]), 0)\n",
    "                    self.x_opt_acados = self.x_opt_acados.repeat(self.N, 0)\n",
    "                else:\n",
    "                    self.x_opt_acados = np.hstack(self.target)\n",
    "            if self.w_opt_acados is None:\n",
    "                if len(self.u_target.shape) == 1:\n",
    "                    self.w_opt_acados = self.u_target[np.newaxis]\n",
    "                    self.w_opt_acados = self.w_opt_acados.repeat(self.N, 0)\n",
    "                else:\n",
    "                    self.w_opt_acados = np.hstack(self.u_target)\n",
    "\n",
    "            gp_state = gp_regression_state if gp_regression_state is not None else initial_state\n",
    "            if not self.mlp_conf['approximated']:\n",
    "                self.acados_ocp_solver[use_model].set(0, 'p', np.hstack([np.array(gp_state + [1])]))\n",
    "                for j in range(1, self.N):\n",
    "                    self.acados_ocp_solver[use_model].set(j, 'p', np.hstack([np.array([0.0] * (len(gp_state) + 1))]))\n",
    "            else:\n",
    "                state = np.vstack([np.array([initial_state]), self.x_opt_acados[1:]])\n",
    "                a_list = []\n",
    "                for i in range(state.shape[0]):\n",
    "                    a_list.append(v_dot_q(np.array(state[i, 7:10]), quaternion_inverse(np.array(state[i, 3:7]))))\n",
    "                a = np.array(a_list)[:self.N]\n",
    "\n",
    "                if self.mlp_conf['torque_output']:\n",
    "                    a = np.concatenate([a, state[:self.N, 10:]], axis=-1)\n",
    "\n",
    "                if self.mlp_conf['u_inp']:\n",
    "                    a = np.concatenate([a, self.w_opt_acados], axis=-1)\n",
    "\n",
    "                if self.mlp_conf['ground_map_input']:\n",
    "                    ground_maps = []\n",
    "                    for i in range(state.shape[0]):\n",
    "                        pos = state[i][:3]\n",
    "                        x_idxs = np.floor((pos[0] - self._org_to_map_org[0]) / self._map_res).astype(int) - 1\n",
    "                        y_idxs = np.floor((pos[1] - self._org_to_map_org[1]) / self._map_res).astype(int) - 1\n",
    "                        ground_patch = self._static_ground_map[x_idxs:x_idxs + 3, y_idxs:y_idxs + 3]\n",
    "\n",
    "                        relative_ground_patch = 4 * (np.clip(pos[2] - ground_patch, 0, 0.5) - 0.25)\n",
    "\n",
    "                        flatten_relative_ground_patch = relative_ground_patch.flatten(order='F')\n",
    "\n",
    "                        ground_effect_in = np.hstack([flatten_relative_ground_patch,\n",
    "                                                      flatten_relative_ground_patch[..., :4] * 0])\n",
    "\n",
    "                        ground_maps.append(ground_effect_in)\n",
    "\n",
    "                    a = np.concatenate([a, np.array(ground_maps)[:self.N]], axis=-1)\n",
    "\n",
    "                mlp_params = self.mlp_regressor.approx_params(a, order=self.mlp_conf['approx_order'], flat=True)\n",
    "                mlp_params = np.vstack([mlp_params, mlp_params[[-1]]])\n",
    "                self.acados_ocp_solver[use_model].set(0, 'p',\n",
    "                                                      np.hstack([np.array(gp_state + [1]), mlp_params[0]]))\n",
    "                for j in range(1, self.N):\n",
    "                    self.acados_ocp_solver[use_model].set(j, 'p', np.hstack([np.array([0.0] * (len(gp_state) + 1)),\n",
    "                                                                             mlp_params[j]]))\n",
    "\n",
    "        # Solve OCP\n",
    "        self.acados_ocp_solver[use_model].solve()\n",
    "\n",
    "        # Get u\n",
    "        w_opt_acados = np.ndarray((self.N, 4))\n",
    "        x_opt_acados = np.ndarray((self.N + 1, len(x_init)))\n",
    "        x_opt_acados[0, :] = self.acados_ocp_solver[use_model].get(0, \"x\")\n",
    "        for i in range(self.N):\n",
    "            w_opt_acados[i, :] = self.acados_ocp_solver[use_model].get(i, \"u\")\n",
    "            x_opt_acados[i + 1, :] = self.acados_ocp_solver[use_model].get(i + 1, \"x\")\n",
    "\n",
    "        self.x_opt_acados = x_opt_acados.copy()\n",
    "        self.w_opt_acados = w_opt_acados.copy()\n",
    "\n",
    "        w_opt_acados = np.reshape(w_opt_acados, (-1))\n",
    "        return w_opt_acados if not return_x else (w_opt_acados, x_opt_acados)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4099915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_352256/627214486.py:269: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_gru.load_state_dict(torch.load(save_path, map_location=device))   # 2) load weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model reloaded and ready for inference on cuda\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "DeepGRURegressor0527.forward() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 320\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean iteration time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m1000\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean(opt_times)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mms -- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean(opt_times)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.0f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mHz)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 320\u001b[0m     \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 277\u001b[0m, in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    273\u001b[0m MPC_Horizon \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m    275\u001b[0m model_CasADi \u001b[38;5;241m=\u001b[39m l4c\u001b[38;5;241m.\u001b[39mrealtime\u001b[38;5;241m.\u001b[39mRealTimeL4CasADi(model_gru, approximation_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 277\u001b[0m solver \u001b[38;5;241m=\u001b[39m MPC(model\u001b[38;5;241m=\u001b[39m\u001b[43mmodel_CasADi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, MPC_Horizon \u001b[38;5;241m=\u001b[39m MPC_Horizon)\u001b[38;5;241m.\u001b[39msolver\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWarming up model...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    280\u001b[0m x_l \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniforge3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1714\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1712\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1713\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1725\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1720\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1723\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1724\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1728\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: DeepGRURegressor0527.forward() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "import casadi as cs\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import l4casadi as l4c\n",
    "from acados_template import AcadosSimSolver, AcadosOcpSolver, AcadosSim, AcadosOcp, AcadosModel\n",
    "import time\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "\n",
    "\n",
    "class DeepGRURegressor0527(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int = 1,\n",
    "        hidden_size: int = 64,\n",
    "        num_layers: int = 6,\n",
    "        dropout: float = 0.3,\n",
    "        bidirectional: bool = False,\n",
    "        fc_hidden_dims: list[int] = [512, 256, 64, 32, 32]\n",
    "    ):\n",
    "        \"\"\"\n",
    "        A deep GRU-based regressor with configurable GRU depth, directionality,\n",
    "        and an MLP head of arbitrary hidden dimensions.\n",
    "        \n",
    "        Args:\n",
    "            input_size:    Number of features in the input sequence.\n",
    "            hidden_size:   Number of features in the GRU hidden state.\n",
    "            num_layers:    Number of stacked GRU layers.\n",
    "            dropout:       Dropout probability between GRU layers and in MLP.\n",
    "            bidirectional: If True, uses a bidirectional GRU (doubles hidden output).\n",
    "            fc_hidden_dims: List of hidden sizes for the MLP head.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.bidirectional = bidirectional\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "            bidirectional=bidirectional,\n",
    "        )\n",
    "\n",
    "        # Determine the input dimension to the first FC layer\n",
    "        fc_in_dim = hidden_size * (2 if bidirectional else 1)\n",
    "\n",
    "        # Build MLP head\n",
    "        layers = []\n",
    "        for h_dim in fc_hidden_dims:\n",
    "            layers += [\n",
    "                nn.Linear(fc_in_dim, h_dim),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(dropout),\n",
    "            ]\n",
    "            fc_in_dim = h_dim\n",
    "        layers.append(nn.Linear(fc_in_dim, 1))\n",
    "\n",
    "        self.fc = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, hidden:torch.Tensor = None ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        Args:\n",
    "            x: Tensor of shape (batch, seq_len, input_size)\n",
    "        Returns:\n",
    "            preds: Tensor of shape (batch,) with the regression output.\n",
    "            hidden: (num_layers, batch, hidden_size) or None\n",
    "        \"\"\"\n",
    "        # GRU returns: output (batch, seq_len, num_directions*hidden_size), h_n\n",
    "        B = x.size(0)\n",
    "        if hidden is not None and hidden.size(1) == B:\n",
    "            hidden = hidden.detach()\n",
    "        else:\n",
    "            hidden = None\n",
    "        out,_ = self.gru(x)\n",
    "        y_seq = self.fc(out)         # (B, seq_len, 1)\n",
    "        y_seq = y_seq.squeeze(-1)    # (B, seq_len)\n",
    "        return y_seq, hidden\n",
    "\n",
    "class MPC:\n",
    "    def __init__(self, model, N):\n",
    "        self.N = N\n",
    "        self.model = model\n",
    "\n",
    "    @property\n",
    "    def solver(self):\n",
    "        return AcadosOcpSolver(self.ocp())\n",
    "\n",
    "    def ocp(self):\n",
    "        model = self.model\n",
    "\n",
    "\n",
    "\n",
    "def run():\n",
    "\n",
    "    # -------- Load the previously trained GRU model --------------------------------------\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    save_path = os.path.join(\"save\", \"gru_regressor_0527.pth\")\n",
    "    model_gru = DeepGRURegressor0527()                                      # 1) re-create the model with the same architecture\n",
    "    model_gru.load_state_dict(torch.load(save_path, map_location=device))   # 2) load weights   \n",
    "    model_gru.to(device).eval()                                             # 3) move to device & eval\n",
    "    print(\"Model reloaded and ready for inference on\", device)\n",
    "\n",
    "    MPC_Horizon = 10\n",
    "\n",
    "    model_CasADi = l4c.realtime.RealTimeL4CasADi(model_gru, approximation_order=2)\n",
    "\n",
    "    solver = MPC(model=model_CasADi.model(), MPC_Horizon = MPC_Horizon).solver\n",
    "\n",
    "\n",
    "    x = []\n",
    "    x_ref = []\n",
    "    ts = 1. / N\n",
    "    xt = np.array([1., 0.])\n",
    "    opt_times = []\n",
    "\n",
    "    for i in range(50):\n",
    "        now = time.time()\n",
    "        t = np.linspace(i * ts, i * ts + 1., 10)\n",
    "        yref = np.sin(0.5 * t + np.pi / 2)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae3e935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model reloaded and ready for inference on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_352256/1129356520.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_gru.load_state_dict(torch.load(save_path, map_location=device))   # 2) load weights\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "save_path = os.path.join(\"save\", \"gru_regressor_0527.pth\")\n",
    "model_gru = DeepGRURegressor0527()                                      # 1) re-create the model with the same architecture\n",
    "model_gru.load_state_dict(torch.load(save_path, map_location=device))   # 2) load weights   \n",
    "model_gru.to(device).eval()                                             # 3) move to device & eval\n",
    "print(\"Model reloaded and ready for inference on\", device)\n",
    "\n",
    "MPC_Horizon = 10\n",
    "\n",
    "model_CasADi = l4c.realtime.RealTimeL4CasADi(model_gru, approximation_order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5105c321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import casadi as cs\n",
    "import numpy as np\n",
    "import torch\n",
    "import l4casadi as l4c\n",
    "from acados_template import AcadosSimSolver, AcadosOcpSolver, AcadosSim, AcadosOcp, AcadosModel\n",
    "import time\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "\n",
    "class PyTorchModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_layer = torch.nn.Linear(2, 512)\n",
    "\n",
    "        hidden_layers = []\n",
    "        for i in range(5):\n",
    "            hidden_layers.append(torch.nn.Linear(512, 512))\n",
    "\n",
    "        self.hidden_layer = torch.nn.ModuleList(hidden_layers)\n",
    "        self.out_layer = torch.nn.Linear(512, 2)\n",
    "\n",
    "        # Model is not trained -- setting output to zero\n",
    "        with torch.no_grad():\n",
    "            self.out_layer.bias.fill_(0.)\n",
    "            self.out_layer.weight.fill_(0.)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        for layer in self.hidden_layer:\n",
    "            x = torch.tanh(layer(x))\n",
    "        x = self.out_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DoubleIntegratorWithLearnedDynamics:\n",
    "    def __init__(self, learned_dyn):\n",
    "        self.learned_dyn = learned_dyn\n",
    "\n",
    "    def model(self):\n",
    "        s = cs.MX.sym('s', 1)\n",
    "        s_dot = cs.MX.sym('s_dot', 1)\n",
    "        s_dot_dot = cs.MX.sym('s_dot_dot', 1)\n",
    "        u = cs.MX.sym('u', 1)\n",
    "        x = cs.vertcat(s, s_dot)\n",
    "        x_dot = cs.vertcat(s_dot, s_dot_dot)\n",
    "\n",
    "        res_model = self.learned_dyn(x)\n",
    "        p = self.learned_dyn.get_sym_params()\n",
    "        parameter_values = self.learned_dyn.get_params(np.array([0, 0]))\n",
    "\n",
    "        f_expl = cs.vertcat(\n",
    "            s_dot,\n",
    "            u\n",
    "        ) + res_model\n",
    "\n",
    "        x_start = np.zeros((2))\n",
    "\n",
    "        # store to struct\n",
    "        model = cs.types.SimpleNamespace()\n",
    "        model.x = x\n",
    "        model.xdot = x_dot\n",
    "        model.u = u\n",
    "        model.z = cs.vertcat([])\n",
    "        model.p = p\n",
    "        model.parameter_values = parameter_values\n",
    "        model.f_expl = f_expl\n",
    "        model.x_start = x_start\n",
    "        model.constraints = cs.vertcat([])\n",
    "        model.name = \"wr\"\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "class MPC:\n",
    "    def __init__(self, model, N):\n",
    "        self.N = N\n",
    "        self.model = model\n",
    "\n",
    "    @property\n",
    "    def simulator(self):\n",
    "        return AcadosSimSolver(self.sim())\n",
    "\n",
    "    @property\n",
    "    def solver(self):\n",
    "        return AcadosOcpSolver(self.ocp())\n",
    "\n",
    "    def sim(self):\n",
    "        model = self.model\n",
    "\n",
    "        t_horizon = 1.\n",
    "        N = self.N\n",
    "\n",
    "        # Get model\n",
    "        model_ac = self.acados_model(model=model)\n",
    "        model_ac.p = model.p\n",
    "\n",
    "        # Dimensions\n",
    "        nx = 2\n",
    "        nu = 1\n",
    "        ny = 1\n",
    "\n",
    "        # Create OCP object to formulate the optimization\n",
    "        sim = AcadosSim()\n",
    "        sim.model = model_ac\n",
    "        sim.dims.N = N\n",
    "        sim.dims.nx = nx\n",
    "        sim.dims.nu = nu\n",
    "        sim.dims.ny = ny\n",
    "        sim.solver_options.tf = t_horizon\n",
    "\n",
    "        # Solver options\n",
    "        sim.solver_options.Tsim = 1./ 10.\n",
    "        sim.solver_options.qp_solver = 'FULL_CONDENSING_HPIPM'\n",
    "        sim.solver_options.hessian_approx = 'GAUSS_NEWTON'\n",
    "        sim.solver_options.integrator_type = 'ERK'\n",
    "        # ocp.solver_options.print_level = 0\n",
    "        sim.solver_options.nlp_solver_type = 'SQP_RTI'\n",
    "\n",
    "        return sim\n",
    "\n",
    "    def ocp(self):\n",
    "        model = self.model\n",
    "\n",
    "        t_horizon = 1.\n",
    "        N = self.N\n",
    "\n",
    "        # Get model\n",
    "        model_ac = self.acados_model(model=model)\n",
    "        model_ac.p = model.p\n",
    "\n",
    "        # Dimensions\n",
    "        nx = 2\n",
    "        nu = 1\n",
    "        ny = 1\n",
    "\n",
    "        # Create OCP object to formulate the optimization\n",
    "        ocp = AcadosOcp()\n",
    "        ocp.model = model_ac\n",
    "        ocp.dims.N = N\n",
    "        ocp.dims.nx = nx\n",
    "        ocp.dims.nu = nu\n",
    "        ocp.dims.ny = ny\n",
    "        ocp.solver_options.tf = t_horizon\n",
    "\n",
    "        # Initialize cost function\n",
    "        ocp.cost.cost_type = 'LINEAR_LS'\n",
    "        ocp.cost.cost_type_e = 'LINEAR_LS'\n",
    "\n",
    "        ocp.cost.W = np.array([[1.]])\n",
    "\n",
    "        ocp.cost.Vx = np.zeros((ny, nx))\n",
    "        ocp.cost.Vx[0, 0] = 1.\n",
    "        ocp.cost.Vu = np.zeros((ny, nu))\n",
    "        ocp.cost.Vz = np.array([[]])\n",
    "        ocp.cost.Vx_e = np.zeros((ny, nx))\n",
    "        ocp.cost.W_e = np.array([[0.]])\n",
    "        ocp.cost.yref_e = np.array([0.])\n",
    "\n",
    "        # Initial reference trajectory (will be overwritten)\n",
    "        ocp.cost.yref = np.zeros(1)\n",
    "\n",
    "        # Initial state (will be overwritten)\n",
    "        ocp.constraints.x0 = model.x_start\n",
    "\n",
    "        # Set constraints\n",
    "        a_max = 10\n",
    "        ocp.constraints.lbu = np.array([-a_max])\n",
    "        ocp.constraints.ubu = np.array([a_max])\n",
    "        ocp.constraints.idxbu = np.array([0])\n",
    "\n",
    "        # Solver options\n",
    "        ocp.solver_options.qp_solver = 'FULL_CONDENSING_HPIPM'\n",
    "        ocp.solver_options.hessian_approx = 'GAUSS_NEWTON'\n",
    "        ocp.solver_options.integrator_type = 'ERK'\n",
    "        ocp.solver_options.nlp_solver_type = 'SQP_RTI'\n",
    "\n",
    "        ocp.parameter_values = model.parameter_values\n",
    "\n",
    "        return ocp\n",
    "\n",
    "    def acados_model(self, model):\n",
    "        model_ac = AcadosModel()\n",
    "        model_ac.f_impl_expr = model.xdot - model.f_expl\n",
    "        model_ac.f_expl_expr = model.f_expl\n",
    "        model_ac.x = model.x\n",
    "        model_ac.xdot = model.xdot\n",
    "        model_ac.u = model.u\n",
    "        model_ac.name = model.name\n",
    "        return model_ac\n",
    "\n",
    "\n",
    "def run():\n",
    "    N = 10\n",
    "\n",
    "    learned_dyn_model = l4c.realtime.RealTimeL4CasADi(PyTorchModel(), approximation_order=1)\n",
    "\n",
    "    model = DoubleIntegratorWithLearnedDynamics(learned_dyn_model)\n",
    "    solver = MPC(model=model.model(), N=N).solver\n",
    "\n",
    "    print('Warming up model...')\n",
    "    x_l = []\n",
    "    for i in range(N):\n",
    "        x_l.append(solver.get(i, \"x\"))\n",
    "    for i in range(20):\n",
    "        learned_dyn_model.get_params(np.stack(x_l, axis=0))\n",
    "    print('Warmed up!')\n",
    "\n",
    "    x = []\n",
    "    x_ref = []\n",
    "    ts = 1. / N\n",
    "    xt = np.array([1., 0.])\n",
    "    opt_times = []\n",
    "\n",
    "    for i in range(50):\n",
    "        now = time.time()\n",
    "        t = np.linspace(i * ts, i * ts + 1., 10)\n",
    "        yref = np.sin(0.5 * t + np.pi / 2)\n",
    "        x_ref.append(yref[0])\n",
    "        for t, ref in enumerate(yref):\n",
    "            solver.set(t, \"yref\", ref)\n",
    "        solver.set(0, \"lbx\", xt)\n",
    "        solver.set(0, \"ubx\", xt)\n",
    "        solver.solve()\n",
    "        xt = solver.get(1, \"x\")\n",
    "        x.append(xt)\n",
    "\n",
    "        x_l = []\n",
    "        for i in range(N):\n",
    "            x_l.append(solver.get(i, \"x\"))\n",
    "        params = learned_dyn_model.get_params(np.stack(x_l, axis=0))\n",
    "        for i in range(N):\n",
    "            solver.set(i, \"p\", params[i])\n",
    "\n",
    "        elapsed = time.time() - now\n",
    "        opt_times.append(elapsed)\n",
    "\n",
    "    print(f'Mean iteration time: {1000*np.mean(opt_times):.1f}ms -- {1/np.mean(opt_times):.0f}Hz)')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f39d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── PyTorch GRU REGRESSOR DEFINITION & LOADING ────────────────────────────────\n",
    "class GRURegressor(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=128, num_layers=2, output_size=1):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers,\n",
    "                          batch_first=True)\n",
    "        self.fc  = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        # x: [batch, seq_len, input_size]\n",
    "        out, h = self.gru(x, h)           # out: [batch, seq_len, hidden_size]\n",
    "        out = self.fc(out)                # out: [batch, seq_len, output_size]\n",
    "        return out, h\n",
    "\n",
    "def load_model(path, device):\n",
    "    # instantiate model with the exact same hyperparameters as training\n",
    "    model = GRURegressor(input_size=1,\n",
    "                         hidden_size=128,\n",
    "                         num_layers=2,\n",
    "                         output_size=1).to(device)\n",
    "    state = torch.load(path, map_location=device)\n",
    "    # if you saved state_dict:\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# ─── SIMPLE RANDOM-SHOOTING MPC FUNCTION ───────────────────────────────────────\n",
    "\n",
    "def mpc_step(model, elapsed_time, ref_time, ref_speed,\n",
    "             horizon=10, num_candidates=30,\n",
    "             u_min=-15.0, u_max=100.0, Ts=0.01, device='cpu'):\n",
    "    \"\"\"\n",
    "    Random-shooting MPC:\n",
    "      • samples `num_candidates` PWM sequences of length `horizon`\n",
    "      • rolls them through the GRU model to predict speeds\n",
    "      • computes sum-of-squared tracking error against the reference\n",
    "      • returns the first control move of the best sequence.\n",
    "    \"\"\"\n",
    "    # 1) build future reference vector\n",
    "    ref_future = np.array([\n",
    "        float(np.interp(elapsed_time + Ts*(i+1), ref_time, ref_speed))\n",
    "        for i in range(horizon)\n",
    "    ], dtype=np.float32)  # shape (horizon,)\n",
    "\n",
    "    # 2) sample candidate sequences in [u_min, u_max]\n",
    "    cands = np.random.uniform(u_min, u_max,\n",
    "                              size=(num_candidates, horizon)).astype(np.float32)\n",
    "\n",
    "    # 3) roll out each candidate, compute cost\n",
    "    costs = np.zeros(num_candidates, dtype=np.float32)\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_candidates):\n",
    "            u_seq = torch.from_numpy(cands[i:i+1, :]) \\\n",
    "                       .unsqueeze(2).to(device)  # [1, horizon, 1]\n",
    "            preds, _ = model(u_seq)    # [1, horizon, 1]\n",
    "            v_pred = preds.squeeze(0).squeeze(1).cpu().numpy()  # (horizon,)\n",
    "            costs[i] = np.sum((v_pred - ref_future)**2)\n",
    "    # 4) pick best and return its first element\n",
    "    best_idx = int(np.argmin(costs))\n",
    "    return float(cands[best_idx, 0])\n",
    "\n",
    "def mpc_control(past_u, ref_times, ref_speeds, elapsed_time, Ts, model, Np):\n",
    "    \"\"\"\n",
    "    Simple receding-horizon MPC: assume model takes input sequence of length Np and predicts Np future speeds.\n",
    "    We optimize the first control move by fitting a constant-u sequence over horizon.\n",
    "    \"\"\"\n",
    "    # future reference\n",
    "    t_future = elapsed_time + np.arange(1, Np+1) * Ts\n",
    "    r_future = np.interp(t_future, ref_times, ref_speeds)\n",
    "\n",
    "    def cost(u_seq):\n",
    "        # prepare input: shape [1, Np, 1]\n",
    "        u_in = torch.tensor(u_seq[None, :, None], dtype=torch.float32, device=device)\n",
    "        with torch.no_grad():\n",
    "            v_pred = model(u_in).cpu().numpy().flatten()\n",
    "        return np.sum((v_pred - r_future)**2)\n",
    "\n",
    "    # init guess: keep previous input\n",
    "    u0 = np.ones(Np, dtype=float) * past_u[-1]\n",
    "    bounds = [(-15.0, 100.0)] * Np\n",
    "    res = minimize(cost, u0, bounds=bounds, options={'maxiter': 10, 'disp': False})\n",
    "    if res.success:\n",
    "        return float(res.x[0])\n",
    "    else:\n",
    "        return float(u0[0])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
